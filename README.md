# 👁️시각 장애인을 위한 AI 기반 충돌 위험 경고 시스템👁️

**실시간 영상 분석을 통해 시각 장애인의 보행 안전을 돕는 AI 애플리케이션을 개발하는 과정입니다.**

이 프로젝트는 스마트폰 앱(카메라 기능)을 통해 주변 환경을 실시간으로 분석하고, 사용자에게 잠재적인 충돌 위험 객체를 음성으로 경고하여 보다 안전한 보행을 지원하는 것을 목표로 개발하고 있습니다.<br>
해당 저장소는 개발 과정을 순차적으로 담고 있으며, 아직 개발중에 있습니다.

<p align="center"><img src="./statics/yolo+DeepSortW640,S200.gif" width="700"><br><em>현재 진행 현황; 하단의 파란 사각형을 사용자의 근접 영역으로 정의하고 접근한 객체만 박스로 바운딩하고 있음</em></p>

---

## 1. 주요 기능

- **실시간 객체 탐지**: **YOLOv8** 모델을 사용하여 사람, 자동차, 자전거 등 보행 중 마주칠 수 있는 다양한 객체를 실시간으로 탐지합니다.
- **충돌 위험 객체 필터링**: 탐지된 여러 객체 중 사용자에게 실질적인 위협이 될 수 있는 특정 객체들(예: 자동차, 오토바이)을 선별합니다.
- **근접 객체 판단**: **MiDaS** 깊이 추정 모델 등을 활용하여 객체와 사용자 간의 거리를 예측하고, 일정 거리 이내로 접근한 객체를 위험으로 판단합니다.
- **객체 추적 및 경로 예측**: **DeepSort** 알고리즘으로 특정 객체의 움직임을 지속적으로 추적하여 사용자와의 충돌 방향과 가능성을 더욱 세밀하게 분석하여 예측합니다.
- **음성 경고 시스템**: 위험이 감지되면 **TTS(Text-to-Speech)** 기술을 통해 즉각적인 음성 경고를 제공합니다. 영상 처리와 음성 출력이 동시에 원활하게 이루어지도록 **멀티스레딩**을 적용했습니다.

---

## 2. 사용된 기술

- **프로그래밍 언어**: Python
- **메인 라이브러리**: OpenCV, PyTorch, NumPy
- **객체 탐지 (Object Detection)**: YOLOv8
- **깊이 추정 (Depth Estimation)**: MiDaS
- **객체 추적 (Object Tracking)**: DeepSort
- **음성 출력 (Text-to-Speech)**: gTTS, pyttsx3 등

---

## 3. 시작하기

### 1) 사전 요구 사항

- Python 3.8 이상
- pip 가 최신 버전인지 확인하는 것을 권장
```bash
pip install --upgrade pip
```
- git

### 2) 설치 가이드

**💡 권장 사항**
- 가상 환경 사용: 프로젝트별로 독립된 개발 환경을 구성하기 위해 venv나 conda 같은 가상 환경 내에 설치하는 것을 권장합니다.

1.  **프로젝트 클론**
    ```bash
    git clone https://github.com/JeyunH/AI_BlindHelper.git
    ```
    
2.  **주피터 노트북 or 주피터 랩 설치**
    ```bash
    pip install jupyter
    ```
    or
    ```bash
    pip install jupyterlab
    ```
    
3.  **필요한 라이브러리 설치**<br>
    주피터 노트북에서 [**1_라이브러리 환경 셋팅.ipynb**] 파일을 실행 <br>
    *(주의: pytorch 라이브러리를 설치할 때, 자신의 cuda 버전에 맞게 설치해야 합니다. https://pytorch.org/get-started/previous-versions/ 참조)*

---

## 4. 실행 방법

- **각 주피터노트북 파일 실행**
- **웹캠 또는 테스트용 동영상 파일 필요**
---

## 5. 프로젝트 진행 과정

이 프로젝트는 다음과 같은 단계별 기능 구현을 통해 개발되었습니다.

1.  **기본 환경 설정**: 개발에 필요한 라이브러리 및 환경 구축
2.  **실시간 영상 처리**: 웹캠 영상을 받아와 화면에 표시
3.  **객체 탐지 적용 (YOLOv8)**: 실시간 영상에서 객체 탐지 기능 구현
4.  **위험 객체 선별**: 특정 클래스의 객체만 필터링하여 표시
5.  **근접 판단 (MiDaS)**: 깊이 추정 모델을 결합하여 가까운 객체 식별
6.  **음성 경고 추가 (TTS)**: 위험 상황 발생 시 음성으로 알림 (초기 단일 스레드)
7.  **성능 개선 (Multithreading)**: 음성 출력 시 영상이 멈추는 문제를 멀티스레딩으로 해결
8.  **객체 추적 (DeepSort)**: 탐지된 객체의 이동 경로를 추적하는 기능 추가
9.  **최종 시스템 통합**: 객체 탐지, 추적, 근접 판단, 음성 경고 기능을 모두 통합하여 최종 애플리케이션 완성

---

## 🧑‍💻 개발자
*   **황제윤** ([@JeyunH](https://github.com/JeyunH))
*   폴리텍 성남 하이테크과정[인공지능소프트웨어과]
